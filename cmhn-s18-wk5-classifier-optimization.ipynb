{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4988daf4-346a-4a15-b8f8-4802ccdfb87b"
    }
   },
   "source": [
    "# Classifier Optimization\n",
    "\n",
    "In earlier exercises, we explored a variety of classifiers and feature selection techniques. During the past exercises we didn't pay much attention to the parameters of these procedures. In what follows we are going to investigate data-driven, unbiased techniques to optimize classification pipelines.\n",
    "\n",
    "Cross-vaidation can allow us to pick the best performing parameters in in an unbiased fashion. We will be using the useful features from scikit-learn to build up some cross-validation analyses. scikit-learn also offers a simple procedure for building and automating the various steps involved in classifier optimization (e.g. data scaling => feature selection => parameter tuning). This is part of the [Pipeline package](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline). We will also explore these methods in this exercise.\n",
    "\n",
    "## Goal of this script\n",
    ">Build a pipeline of steps to optimize classifier performance.    \n",
    ">Use the pipleline to make optimal choices.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "1f7f9d75-833f-410f-8988-58c1618fa753"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "\n",
    "# Import machine learning libraries\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make preprocessing pipeline\n",
    "\n",
    "In past weeks we have preprocessed the fMRI data from Kim et al. (2017) using the following steps:  \n",
    ">Extract the BOLD data for a mask.  \n",
    ">Get the the stimulus labels.  \n",
    ">Assign a label to every TR.  \n",
    ">Shift the label time course to take account of the hemodynamic lag.  \n",
    ">Extract BOLD data only for the conditions of interest (ignore the TRs corresponding to the baseline).  \n",
    ">Average stimuli within blocks in order to reduce concerns around temporal autocorrelation.\n",
    "\n",
    "In general it can be useful to make a script that contains all of the functions you might use across multiple scripts. This is so that if you make an update to the function, you don't have to update all of the versions in the scripts that might otherwise define the function. Often these will be python scripts called *utils.py*\n",
    "\n",
    "**Exercise 1:** Add all of the functions necessary for data handling (same as last assignment) to the *utils.py* script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import load_data, load_labels, label2TR, shift_timing, reshape_data, blockwise_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data from one participant ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  sub-01\n",
      "Processing Start ...\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-01/preprocessed/loc/sub-01_filtered2_d1_firstExampleFunc_r1.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-01/preprocessed/loc/sub-01_filtered2_d1_firstExampleFunc_r2.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-01/preprocessed/loc/sub-01_filtered2_d1_firstExampleFunc_r3.nii\n",
      "sub-01 = TRs:  930 ; Voxels:  177314\n",
      "Expected blocks: 45; Resampled blocks: 45\n"
     ]
    }
   ],
   "source": [
    "# Preset variables\n",
    "dir = '/gpfs/milgram/data/cmhn-s18/datasets/vdc/'\n",
    "num_runs=3\n",
    "TR=1.5\n",
    "hrf_lag = 4.5  # In seconds what is the lag between a stimulus onset and the peak bold response\n",
    "shift_size = int(hrf_lag / TR) # Convert the shift into TRs\n",
    "\n",
    "sub_id = 1\n",
    "\n",
    "# Convert the number into a participant folder name\n",
    "if (sub_id < 10):\n",
    "    sids = '0' + str(sub_id)\n",
    "else:\n",
    "    sids = str(sub_id)   \n",
    "\n",
    "# Specify the subject name\n",
    "sub = 'sub-' + sids\n",
    "\n",
    "# Load subject labels\n",
    "stim_label_allruns = load_labels(dir, sub)\n",
    "\n",
    "# Load the fMRI data\n",
    "epi_mask_data_all = load_data(directory=dir, subject_name=sub, mask_name='', zscore_data=True)\n",
    "\n",
    "# How many events are there on this run\n",
    "_, events = stim_label_allruns.shape\n",
    "events_run = int(events / num_runs)\n",
    "\n",
    "# This can differ per participant\n",
    "print(sub, '= TRs: ', epi_mask_data_all.shape[1], '; Voxels: ', epi_mask_data_all.shape[0])\n",
    "TRs_run = int(epi_mask_data_all.shape[1] / num_runs)\n",
    "\n",
    "# Convert the timing into TR indexes\n",
    "stim_label_TR = label2TR(stim_label_allruns, num_runs, TR, TRs_run, events_run)\n",
    "\n",
    "# Shift the data some amount\n",
    "stim_label_TR_shifted = shift_timing(stim_label_TR, shift_size)\n",
    "\n",
    "# Perform the reshaping of the data\n",
    "bold_data, labels = reshape_data(stim_label_TR_shifted, epi_mask_data_all)\n",
    "\n",
    "# Down sample the data to be blockwise rather than trialwise\n",
    "bold_data, labels = blockwise_sampling(bold_data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big should a training set be?\n",
    "\n",
    "When we split up our data into training and test sets we are trying to strike a balance between giving our classifier enough data to train a model with precise parameter estimates while ensuring that we also have enough data so that our test statistic has low variance. But what is that balance? Generally we use a rule of thumb that between 10% and 20% of our dataset should be the test. However, let's now investigate how different training set size affects classifier performance!\n",
    "\n",
    "Aside: Not only do your training samples need to be independent, but so do your test samples. If the test samples are highly correlated then the effective number of test samples is lower and the test statistic variance will be higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a basic n fold classification\n",
    "def classification(classifier, data, labels, n_folds = 5, test_size=0.2):\n",
    "    \n",
    "    # How many folds of the classifier\n",
    "    skfold = StratifiedShuffleSplit(n_splits=n_folds, test_size=test_size) \n",
    "\n",
    "    clf_score = np.array([])\n",
    "    for train, test in skfold.split(data, labels):\n",
    "\n",
    "        # Pull out the sample data\n",
    "        train_data = data[train, :]\n",
    "        test_data = data[test, :]\n",
    "        \n",
    "        # Train and test the classifier\n",
    "        clf = classifier.fit(train_data, labels[train])\n",
    "        clf_score = np.hstack((clf_score, clf.score(test_data, labels[test])))\n",
    "\n",
    "    return clf_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Examine how the accuracy of the classifier changes with different test set sizes from 10% to 90% in 10% steps. Plot the results. Do this over 10 folds to decrease the variability of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Exercise 2\n",
    "\n",
    "classifier = SVC(kernel=\"linear\", C=0.0001)\n",
    "steps = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "test_results = []\n",
    "\n",
    "for i in range(len(steps)):\n",
    "    score_all = classification(classifier, bold_data, labels, test_size=steps[i])\n",
    "    test_results.append(score_all)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(steps, test_results)\n",
    "plt.xlabel('test size')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "eee6bfd7-e6b6-4860-8501-6a3799dba268"
    }
   },
   "source": [
    "## Cross-Validation: Hyper-parameter selection\n",
    "\n",
    "Each of the classifiers we have used so far has one or more \"hyper-parameters\" used to configure and optimize the model based on the data and our goals. Click [here](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/) for an explanation of the distinction between hyper-parameters and parameters. For instance, regularized logistic regression has a \"penalty\" hyper-parameter, which determines how much to emphasize the weight regularizing expression (e.g., L2 norm) when training the model.\n",
    "\n",
    "**Exercise 3:** SVM has a \"cost\" hyper-parameter, briefly describe what it does:\n",
    "\n",
    "**A:** Cost (C) is how much we penalize the SVM for data points within the margin (where \"within\" can also mean on the wrong side of the dividing hyperplane). For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly. Conversely, a very small value of C will cause the optimizer to look for a larger-margin separating hyperplane, even if that hyperplane misclassifies more points. A lower C gives higher error on the training set and may even misclassify examples that are linearly separable, but it finds a larger margin that might be more robust.\n",
    "\n",
    "From https://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel and https://www.quora.com/What-is-the-intuition-behind-the-Cost-and-Gamma-parameters-in-SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to pick the best cost hyper-parameter for our dataset and to do this we will use cross-validation. Each hyper-parameter can be considered as a dimension such that the set of hyper-parameters is a space to be searched for effective values. The GridSearchCV method in scikit-learn explores this space by dividing it up into a grid of values to be searched exhaustively. \n",
    "\n",
    "To give you an intuition for how grid search works, imagine trying to figure out what climate you find most comfortable. Let's say that there are two (hyper-)parameters that seem relevant: temperature and humidity. A given climate can be defined by the combination of values of these two parameters and you could report how comfortable you find this climate. A grid search would involve changing the value of each parameter with respect to the other in some fixed step size (e.g., 60 degrees and 50% humidity, 60 degrees and 60% humidity, 65 degrees and 60% humidity, etc.) and evaluating your preference for each combination.  \n",
    "\n",
    "Note that the number of steps and hyper-parameters to search is up to you. But be aware of combinatorial explosion: the granularity of the search (the smaller the steps) and the number of hyper-parameters considered increases the search time exponentially.\n",
    "\n",
    "GridSearchCV is an *extremely* useful tool for hyper-parameter optimization because it is very flexible. You can look at different values of a hyper-parameter, different kernels, different training/test split sizes, etc. The input is a dictionary where the key is the parameter of interest (the sides of the grid) and the values are the parameter increments to search over (the steps of the grid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Grid search can be slow because it returns results for all possible combinations of hyper-parameters. Can you think of a more efficient way to find the good hyper-parameter settings (Hint: How can you narrow the search?)\n",
    "\n",
    "**A:** Suppose you have four parameters, A, B, C, and D. One could start by choosing arbitrary values for B-D and scanning along A. Find the optimal value of a for those B-D. Then hold A, C, and D fixed, and scan along B to find the optimum. Do the same for C and D while holding all other variables fixed. This avoids combinatorial explosion (for n values of each parameter and m parameters, you only have to test n x m combinations, instead of n^m combinations). However, it comes at the risk of missing global optima if your error surface is highly convoluted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are going to do a grid search over the SVM cost parameter and investigate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search over different cost parameters\n",
    "parameters = {'C':[0.01, 0.1, 1, 10]}\n",
    "clf = GridSearchCV(SVC(kernel='linear'),\n",
    "                   parameters,\n",
    "                   cv=StratifiedShuffleSplit(n_splits=3, test_size=0.1))\n",
    "clf.fit(bold_data, labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output contains information about the best hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.666666666667\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)  # What was the best classifier and cost?\n",
    "print(clf.best_score_) # What was the best classification score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to see more details from the cross validation? All the results are stored in the dictionary cv\\_results\\_. Let's took a look at some of the important metrics stored here. For more details you can look at the method on scikit-learn [here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "\n",
    "You can printout cv\\_results\\_ directly or for a nicer look you can import it into a pandas dataframe and print it out. Each row corresponds to one parameter combination.\n",
    "\n",
    "(Pandas is a widely used data processing and machine learning package. Some people love it more than the animal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'split1_test_score': array([ 0.2,  0.2,  0.2,  0.2]), 'rank_test_score': array([1, 1, 1, 1], dtype=int32), 'split0_train_score': array([ 1.,  1.,  1.,  1.]), 'std_test_score': array([ 0.33993463,  0.33993463,  0.33993463,  0.33993463]), 'split2_train_score': array([ 1.,  1.,  1.,  1.]), 'split2_test_score': array([ 0.8,  0.8,  0.8,  0.8]), 'mean_score_time': array([ 0.03670025,  0.03669246,  0.03672703,  0.03670406]), 'std_train_score': array([ 0.,  0.,  0.,  0.]), 'mean_train_score': array([ 1.,  1.,  1.,  1.]), 'split0_test_score': array([ 1.,  1.,  1.,  1.]), 'params': [{'C': 0.01}, {'C': 0.1}, {'C': 1}, {'C': 10}], 'param_C': masked_array(data = [0.01 0.1 1 10],\n",
      "             mask = [False False False False],\n",
      "       fill_value = ?)\n",
      ", 'mean_fit_time': array([ 0.48453387,  0.47234297,  0.47255286,  0.4717025 ]), 'std_score_time': array([  3.20694407e-05,   1.67870309e-05,   1.30243385e-05,\n",
      "         1.60822124e-05]), 'split1_train_score': array([ 1.,  1.,  1.,  1.]), 'std_fit_time': array([ 0.02403472,  0.00202249,  0.00257178,  0.00272118]), 'mean_test_score': array([ 0.66666667,  0.66666667,  0.66666667,  0.66666667])}\n"
     ]
    }
   ],
   "source": [
    "# Ugly way\n",
    "print(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
      "0       0.484534         0.036700         0.666667               1.0    0.01   \n",
      "1       0.472343         0.036692         0.666667               1.0     0.1   \n",
      "2       0.472553         0.036727         0.666667               1.0       1   \n",
      "3       0.471702         0.036704         0.666667               1.0      10   \n",
      "\n",
      "        params  rank_test_score  split0_test_score  split0_train_score  \\\n",
      "0  {'C': 0.01}                1                1.0                 1.0   \n",
      "1   {'C': 0.1}                1                1.0                 1.0   \n",
      "2     {'C': 1}                1                1.0                 1.0   \n",
      "3    {'C': 10}                1                1.0                 1.0   \n",
      "\n",
      "   split1_test_score  split1_train_score  split2_test_score  \\\n",
      "0                0.2                 1.0                0.8   \n",
      "1                0.2                 1.0                0.8   \n",
      "2                0.2                 1.0                0.8   \n",
      "3                0.2                 1.0                0.8   \n",
      "\n",
      "   split2_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
      "0                 1.0      0.024035        0.000032        0.339935   \n",
      "1                 1.0      0.002022        0.000017        0.339935   \n",
      "2                 1.0      0.002572        0.000013        0.339935   \n",
      "3                 1.0      0.002721        0.000016        0.339935   \n",
      "\n",
      "   std_train_score  \n",
      "0              0.0  \n",
      "1              0.0  \n",
      "2              0.0  \n",
      "3              0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Nicer way\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to do some different types of cross-validation hyper-parameter tuning.\n",
    "\n",
    "**Exercise 5:** In machine learning, kernels are classes of algorithms that can be used to create a model. A radial basis function is a very common kernel in SVM classifiers. Briefly describe what it does:\n",
    "\n",
    "**A:** Linearly non-separable features often become linearly separable after they are mapped to a high dimensional feature space. However, we don't ever need to compute the feature mappings explicitly: we only need to work with their kernels, which are easier to compute. Therefore, it's possible to create a very complex decision boundary based on a high dimensional (even infinite dimensional) feature mapping but still have an efficient computation because of the kernel representation.\n",
    "\n",
    "An RBF kernel on two samples x and x', represented as feature vectors in some input space, is computed as the exponential of the squared Euclidean distance times some parameter -gamma. Since the value of the RBF kernel decreases with distance and ranges between zero (in the limit) and one (when x = x'), it has a ready interpretation as a similarity measure.\n",
    "\n",
    "From http://openclassroom.stanford.edu/MainFolder/DocumentPage.php?course=MachineLearning&doc=exercises/ex8/ex8.html and https://en.wikipedia.org/wiki/Radial_basis_function_kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "# Search over different cost and gamma parameters of a radial basis function\n",
    "parameters = {'gamma':[10e-3, 10e0, 10e3], 'C':[10e-3, 10e0, 10e3]}\n",
    "clf = GridSearchCV(SVC(kernel='rbf'),\n",
    "                   parameters,\n",
    "                   cv=StratifiedShuffleSplit(n_splits=3, test_size=0.1))\n",
    "clf.fit(bold_data, labels)\n",
    "print(clf.best_estimator_)  # What was the best classifier and parameters?\n",
    "print(clf.best_score_) # What was the best classification score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Run an analysis in which you compare linear, polynomial, and RBF kernels for SVM using GridSearchCV. When would linear SVM be expected to outperform other kernels and why?\n",
    "\n",
    "**A:** There are two main cases when linear SVM could outperform other kernels: if the data is linearly separable, or if you misparameterized your SVM (using the wrong gamma and/or cost parameters). There is no reason to say *a priori* that the RBF kernel is best; it just so happens that in most problems the RBF kernel performs best and so people tend to go for it more often than not.\n",
    "\n",
    "From https://stats.stackexchange.com/questions/292480/why-does-svm-linear-kernel-outperforms-svm-rbf-kernel-in-terms-of-classification/292562."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "0.933333333333\n"
     ]
    }
   ],
   "source": [
    "#Exercise 6\n",
    "\n",
    "parameters = {'kernel': ['linear', 'poly', 'rbf']}\n",
    "clf = GridSearchCV(SVC(C=1.0),\n",
    "                   parameters,\n",
    "                   cv=StratifiedShuffleSplit(n_splits=3, test_size=0.1))\n",
    "clf.fit(bold_data, labels)\n",
    "print(clf.best_estimator_)  # What was the best classifier and parameters?\n",
    "print(clf.best_score_) # What was the best classification score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we are writing a classification pipeline, nested cross validation can be very useful. As the name suggests, this procedure nests a second cross-validation within folds of the first cross validation. As before, we will divide data into training and test sets (outer loop), but additionally will divide the training set itself in order to set the hyper-parameters into training and test (or validation) sets (inner loop).\n",
    "\n",
    "Thus, on each split we now have a training (inner), validation (inner), and test (outer) dataset; a typical dataset size distribution might be 60%, 20%, 20%. Within the inner loop we train the model and find the optimal hyper-parameters (i.e., that have the highest performance when tested on the validation data). The typical practice is to then retrain your model with these hyper-parameters on both the training AND validation datasets and then evaluate on your held-out test dataset to get a score.\n",
    "\n",
    "![image](https://qph.ec.quoracdn.net/main-qimg-bb7689c141427db9ab8ab030745aa8bc)\n",
    "\n",
    "This is turtles all the way down, you could have any number of inner loops. However, you will run into data issues quickly (not enough for training) and you will also run the risk of over-fitting your data: you will find the optimal parameters for a small set of your data but this might not generalize to the rest of your data.\n",
    "\n",
    "For more description and a good summary of what you have learnt so far then check [here](http://www.predictiveanalyticsworld.com/patimes/nested-cross-validation-simple-cross-validation-isnt-enough/8952/).\n",
    "\n",
    "**Self-study:** Some people discourage training on both training and validation data, saying you should only ever use the training data for fitting the model. Figure out why these people hold these views."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** Set up a nested cross validation loop. In this loop you will perform hyper-parameter cross validation on a training dataset (which itself will be split into training and validation) and then score these optimized hyper-parameters on the test dataset. Loop through this 10 times and get the average accuracy overall. Note that the optimal hyper-parameter settings for each outer loop fold can be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy on 10 trials in the outer loop is 0.744444 with std. dev. of 0.046878.\n"
     ]
    }
   ],
   "source": [
    "#Exercise 7, adapted from http://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
    "\n",
    "NUM_TRIALS = 10\n",
    "svm = SVC(kernel=\"linear\")\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Arrays to store scores\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Run nested cross-validation\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"LabelKFold\", \"LeaveOneOut\", \"LeaveOneLabelOut\", etc.\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "    clf.fit(bold_data, labels)\n",
    "    nested_score = cross_val_score(clf, X=bold_data, y=labels, cv=outer_cv)\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "print(\"Average accuracy on 10 trials in the outer loop is {0:6f} with std. dev. of {1:6f}.\"\n",
    "      .format(nested_scores.mean(), nested_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to avoid double dipping\n",
    "\n",
    "One of the good things about the GridSearchCV method is that it makes it easy (but not impossible!) to prevent double dipping. In previous exercises we examined cases where double dipping is clear (e.g., training on all of the data and testing on a subset); however, double dipping can be a lot more subtle and harder to detect.\n",
    "\n",
    "For instance, a common form of double dipping is Z scoring over both your training and testing datasets together, rather than Z scoring the two groups separately (in fact we are doing it in this exercise right now!). This is doubling dipping because information from one group affects the other. Imagine a scenario where you were using different runs as your test set. It might be that on a given run that the variability in activity is much higher than in all the other runs. By Z scoring over all runs you are decreasing the variability in all the other runs which could mask any patterns of variability. \n",
    "\n",
    "In practice, Z scoring can be unavoidable: if we have different runs but we don't want to use them as the basis for our training/test splits (for instance because there are practice effects) then we need to combine samples from different runs. Without normalization, these may have wildly different scales due to scanner drift or other confounds, distorting the classifier. Hence we need to normalize within run but this could be considered double dipping because each run includes both training and test data. Even without these concerns about different scales between runs, we might also worry about Z scoring over small numbers of observations in our test set. In the end, Z scoring is double dipping like jaywalking is illegal.\n",
    "\n",
    "**Self-study:** Simulate an example where double dipping with Z scoring affects the results. (Hint: make observations  that are noisy samples of a given pattern of results where the amount of noise varies).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:** If we do a 5 x 6 grid search is there a greater risk of double dipping than if we do a 3 x 2? Are there concerns with overfitting?\n",
    "\n",
    "**A:** A grid search is not double dipping, regardless of the number of instances of each parameter, as long as the model training happens only on the test data. However, there could be concerns with overfitting: the more specifically we fit the model (i.e. with 5 or 6 possible values for each parameter, as opposed to 2 or 3), the greater risk we run that the precise parameters we end up with will not generalize well to the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we work through an exercise of another common type of double dipping in which we perform voxel selection on all of our data before splitting it into a training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.827777777778\n"
     ]
    }
   ],
   "source": [
    "# How many folds of the classifier\n",
    "n_folds = 100\n",
    "test_size = 0.2\n",
    "skfold = StratifiedShuffleSplit(n_splits=n_folds, test_size=test_size) \n",
    "\n",
    "clf_score = np.array([])\n",
    "for train, test in skfold.split(bold_data, labels):\n",
    "    \n",
    "    # Do voxel selection on all voxels\n",
    "    mean_threshold = np.percentile(np.mean(bold_data, axis = 0), 95)\n",
    "    selected_voxels = np.where(mean_threshold <= np.mean(bold_data, axis = 0))\n",
    "    \n",
    "    # Pull out the sample data\n",
    "    train_data = bold_data[train, :]\n",
    "    test_data = bold_data[test, :]\n",
    "\n",
    "    # Train and test the classifier\n",
    "    classifier = SVC(kernel=\"linear\", C=1)\n",
    "    clf = classifier.fit(train_data[:, selected_voxels[0]], labels[train])\n",
    "    score = clf.score(test_data[:, selected_voxels[0]], labels[test])\n",
    "    clf_score = np.hstack((clf_score, score))\n",
    "\n",
    "print(clf_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** Create a copy of this code that fixes the concerns about double dipping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815555555556\n"
     ]
    }
   ],
   "source": [
    "#Exercise 9\n",
    "\n",
    "# How many folds of the classifier\n",
    "n_folds = 100\n",
    "test_size = 0.2\n",
    "skfold = StratifiedShuffleSplit(n_splits=n_folds, test_size=test_size) \n",
    "\n",
    "clf_score = np.array([])\n",
    "for train, test in skfold.split(bold_data, labels):\n",
    "    \n",
    "    # Pull out the sample data\n",
    "    train_data = bold_data[train, :]\n",
    "    test_data = bold_data[test, :]\n",
    "    \n",
    "    # Do voxel selection on training voxels only\n",
    "    mean_threshold = np.percentile(np.mean(train_data, axis = 0), 95)\n",
    "    selected_voxels = np.where(mean_threshold <= np.mean(train_data, axis = 0))\n",
    "\n",
    "    # Train and test the classifier\n",
    "    classifier = SVC(kernel=\"linear\", C=1)\n",
    "    clf = classifier.fit(train_data[:, selected_voxels[0]], labels[train])\n",
    "    score = clf.score(test_data[:, selected_voxels[0]], labels[test])\n",
    "    clf_score = np.hstack((clf_score, score))\n",
    "\n",
    "print(clf_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Pipeline\n",
    "\n",
    "scikit-learn has a method, Pipeline, that simplifies running preprocessing steps in an automated fashion. Below we create a pipeline with the following steps:\n",
    ">Scale the data.  \n",
    ">Use PCA and choose the best option from a set of dimensions.  \n",
    ">Choose the best cost for an SVM.\n",
    "\n",
    "It is then really easy to do cross validation at different levels of this pipeline.\n",
    "\n",
    "The steps below are based on this example in scikit-learn: http://scikit-learn.org/stable/auto_examples/plot_compare_reduction.html#illustration-of-pipeline-and-gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "304fd1c3-80aa-4829-a36a-40c45dde562a"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scale', preprocessing.StandardScaler()),\n",
    "        ('reduce_dim', PCA()),\n",
    "        ('classify', SVC(kernel=\"linear\")),\n",
    "    ])\n",
    "\n",
    "# PCA dimensions\n",
    "component_steps = [20, 40]\n",
    "\n",
    "# Classifier cost options\n",
    "c_steps = [10e-1, 10e0, 10e1, 10e2]\n",
    "\n",
    "# Build the grid search dictionary\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)], \n",
    "        'reduce_dim__n_components': component_steps,\n",
    "        'classify__C': c_steps,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to put it all together and run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('reduce_dim', PCA(copy=True, iterated_power=7, n_components=40, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# parallelization parameter, will return to this later...\n",
    "n_jobs=1;\n",
    "\n",
    "clf_pipe = GridSearchCV(pipe, cv=3, n_jobs=n_jobs, param_grid=param_grid)\n",
    "clf_pipe.fit(bold_data, labels);\n",
    "\n",
    "print(clf_pipe.best_estimator_)  # What was the best classifier and parameters?\n",
    "print(clf_pipe.best_score_) # What was the best classification score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
      "1       0.390021         0.018657         0.600000               1.0   \n",
      "3       0.391802         0.018659         0.600000               1.0   \n",
      "5       0.388710         0.018608         0.600000               1.0   \n",
      "7       0.389886         0.018628         0.600000               1.0   \n",
      "0       0.942122         0.019499         0.466667               1.0   \n",
      "2       0.901483         0.019129         0.466667               1.0   \n",
      "4       0.901486         0.019492         0.466667               1.0   \n",
      "6       0.900900         0.019137         0.466667               1.0   \n",
      "\n",
      "  param_classify__C                                   param_reduce_dim  \\\n",
      "1                 1  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "3                10  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "5               100  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "7              1000  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "0                 1  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "2                10  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "4               100  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "6              1000  PCA(copy=True, iterated_power=7, n_components=...   \n",
      "\n",
      "  param_reduce_dim__n_components  \\\n",
      "1                             40   \n",
      "3                             40   \n",
      "5                             40   \n",
      "7                             40   \n",
      "0                             20   \n",
      "2                             20   \n",
      "4                             20   \n",
      "6                             20   \n",
      "\n",
      "                                              params  rank_test_score  \\\n",
      "1  {'classify__C': 1.0, 'reduce_dim': PCA(copy=Tr...                1   \n",
      "3  {'classify__C': 10.0, 'reduce_dim': PCA(copy=T...                1   \n",
      "5  {'classify__C': 100.0, 'reduce_dim': PCA(copy=...                1   \n",
      "7  {'classify__C': 1000.0, 'reduce_dim': PCA(copy...                1   \n",
      "0  {'classify__C': 1.0, 'reduce_dim': PCA(copy=Tr...                5   \n",
      "2  {'classify__C': 10.0, 'reduce_dim': PCA(copy=T...                5   \n",
      "4  {'classify__C': 100.0, 'reduce_dim': PCA(copy=...                5   \n",
      "6  {'classify__C': 1000.0, 'reduce_dim': PCA(copy...                5   \n",
      "\n",
      "   split0_test_score  split0_train_score  split1_test_score  \\\n",
      "1                0.8                 1.0           0.400000   \n",
      "3                0.8                 1.0           0.400000   \n",
      "5                0.8                 1.0           0.400000   \n",
      "7                0.8                 1.0           0.400000   \n",
      "0                0.6                 1.0           0.333333   \n",
      "2                0.6                 1.0           0.333333   \n",
      "4                0.6                 1.0           0.333333   \n",
      "6                0.6                 1.0           0.333333   \n",
      "\n",
      "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
      "1                 1.0           0.600000                 1.0      0.005581   \n",
      "3                 1.0           0.600000                 1.0      0.003621   \n",
      "5                 1.0           0.600000                 1.0      0.004952   \n",
      "7                 1.0           0.600000                 1.0      0.005329   \n",
      "0                 1.0           0.466667                 1.0      0.046810   \n",
      "2                 1.0           0.466667                 1.0      0.002132   \n",
      "4                 1.0           0.466667                 1.0      0.004146   \n",
      "6                 1.0           0.466667                 1.0      0.004195   \n",
      "\n",
      "   std_score_time  std_test_score  std_train_score  \n",
      "1        0.002518        0.163299              0.0  \n",
      "3        0.002453        0.163299              0.0  \n",
      "5        0.002504        0.163299              0.0  \n",
      "7        0.002508        0.163299              0.0  \n",
      "0        0.000883        0.108866              0.0  \n",
      "2        0.000831        0.108866              0.0  \n",
      "4        0.000540        0.108866              0.0  \n",
      "6        0.000852        0.108866              0.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/apps/hpc/Pypkgs/brainiak/0.5-anaconda/lib/python3.5/site-packages/scikit_learn-0.19.1-py3.5-linux-x86_64.egg/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# What was the best classifier and parameters?\n",
    "cv_results = pd.DataFrame(clf_pipe.cv_results_)\n",
    "\n",
    "# What was the best classification score?\n",
    "print(cv_results.sort_values(by='mean_test_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:** Build a pipeline that takes the following steps:\n",
    "\n",
    "1. Z score the data.  \n",
    "2. Grid search over PCA and the VarianceThreshold method for voxel selection.  \n",
    "3. Grid search over the linear and RBF SVM kernel.\n",
    "\n",
    "Run this pipeline for at least 5 subjects and present your average results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exercise 10\n",
    "\n",
    "# Set up the pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scale', preprocessing.StandardScaler()),\n",
    "        ('reduce_dim', PCA()),\n",
    "        ('classify', SVC()),\n",
    "    ])\n",
    "\n",
    "# PCA dimensions\n",
    "component_steps = [20, 40]\n",
    "\n",
    "# Classifier cost options\n",
    "c_steps = [10e-1, 10e0, 10e1]\n",
    "\n",
    "#threshold\n",
    "var_threshold = np.percentile(np.std(bold_data, axis=0) ** 2, 95)\n",
    "\n",
    "#kernels\n",
    "kernel_types = ['linear', 'rbf']\n",
    "\n",
    "# Build the grid search dictionary\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)],\n",
    "        'reduce_dim__n_components': component_steps,\n",
    "        'classify__C': c_steps,\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [VarianceThreshold(threshold=var_threshold)],\n",
    "        'classify__C': c_steps,\n",
    "    },\n",
    "    {\n",
    "        'classify__kernel': kernel_types\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_subj_data(sub_id):\n",
    "    \n",
    "    dir = '/gpfs/milgram/data/cmhn-s18/datasets/vdc/'\n",
    "\n",
    "    # Convert the number into a participant folder name\n",
    "    if (sub_id < 10):\n",
    "        sids = '0' + str(sub_id)\n",
    "    else:\n",
    "        sids = str(sub_id)   \n",
    "\n",
    "    # Specify the subject name\n",
    "    sub = 'sub-' + sids\n",
    "\n",
    "    # Load subject labels\n",
    "    stim_label_allruns = load_labels(dir, sub)\n",
    "\n",
    "    # Load the fMRI data\n",
    "    epi_mask_data_all = load_data(directory=dir, subject_name=sub, mask_name='', zscore_data=True)\n",
    "\n",
    "    # How many events are there on this run\n",
    "    _, events = stim_label_allruns.shape\n",
    "    events_run = int(events / num_runs)\n",
    "\n",
    "    # This can differ per participant\n",
    "    print(sub, '= TRs: ', epi_mask_data_all.shape[1], '; Voxels: ', epi_mask_data_all.shape[0])\n",
    "    TRs_run = int(epi_mask_data_all.shape[1] / num_runs)\n",
    "\n",
    "    # Convert the timing into TR indexes\n",
    "    stim_label_TR = label2TR(stim_label_allruns, num_runs, TR, TRs_run, events_run)\n",
    "\n",
    "    # Shift the data some amount\n",
    "    stim_label_TR_shifted = shift_timing(stim_label_TR, shift_size)\n",
    "\n",
    "    # Perform the reshaping of the data\n",
    "    bold_data, labels = reshape_data(stim_label_TR_shifted, epi_mask_data_all)\n",
    "\n",
    "    # Down sample the data to be blockwise rather than trialwise\n",
    "    bold_data, labels = blockwise_sampling(bold_data, labels)\n",
    "    \n",
    "    return bold_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  sub-01\n",
      "Processing Start ...\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-01/preprocessed/loc/sub-01_filtered2_d1_firstExampleFunc_r1.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-01/preprocessed/loc/sub-01_filtered2_d1_firstExampleFunc_r2.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-01/preprocessed/loc/sub-01_filtered2_d1_firstExampleFunc_r3.nii\n",
      "sub-01 = TRs:  930 ; Voxels:  177314\n",
      "Expected blocks: 45; Resampled blocks: 45\n",
      "0.6\n",
      "Loaded  sub-02\n",
      "Processing Start ...\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-02/preprocessed/loc/sub-02_filtered2_d1_firstExampleFunc_r1.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-02/preprocessed/loc/sub-02_filtered2_d1_firstExampleFunc_r2.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-02/preprocessed/loc/sub-02_filtered2_d1_firstExampleFunc_r3.nii\n",
      "sub-02 = TRs:  933 ; Voxels:  232022\n",
      "Expected blocks: 45; Resampled blocks: 45\n",
      "0.466666666667\n",
      "Loaded  sub-03\n",
      "Processing Start ...\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-03/preprocessed/loc/sub-03_filtered2_d1_firstExampleFunc_r1.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-03/preprocessed/loc/sub-03_filtered2_d1_firstExampleFunc_r2.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-03/preprocessed/loc/sub-03_filtered2_d1_firstExampleFunc_r3.nii\n",
      "sub-03 = TRs:  933 ; Voxels:  238338\n",
      "Expected blocks: 45; Resampled blocks: 45\n",
      "0.533333333333\n",
      "Loaded  sub-04\n",
      "Processing Start ...\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-04/preprocessed/loc/sub-04_filtered2_d1_firstExampleFunc_r1.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-04/preprocessed/loc/sub-04_filtered2_d1_firstExampleFunc_r2.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-04/preprocessed/loc/sub-04_filtered2_d1_firstExampleFunc_r3.nii\n",
      "sub-04 = TRs:  933 ; Voxels:  244915\n",
      "Expected blocks: 45; Resampled blocks: 45\n",
      "0.488888888889\n",
      "Loaded  sub-05\n",
      "Processing Start ...\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-05/preprocessed/loc/sub-05_filtered2_d1_firstExampleFunc_r1.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-05/preprocessed/loc/sub-05_filtered2_d1_firstExampleFunc_r2.nii\n",
      "/gpfs/milgram/data/cmhn-s18/datasets/vdc/sub-05/preprocessed/loc/sub-05_filtered2_d1_firstExampleFunc_r3.nii\n",
      "sub-05 = TRs:  933 ; Voxels:  211132\n",
      "Expected blocks: 45; Resampled blocks: 45\n",
      "0.733333333333\n"
     ]
    }
   ],
   "source": [
    "n_subjs=5\n",
    "\n",
    "clf_pipe = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "best_scores = np.zeros((n_subjs))\n",
    "\n",
    "for i in range(n_subjs):\n",
    "    bold_data, labels = load_subj_data(i+1)\n",
    "    clf_pipe.fit(bold_data, labels);\n",
    "\n",
    "    # What was the best classification score?\n",
    "    best_scores[i] = clf_pipe.best_score_\n",
    "    print(clf_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('reduce_dim', PCA(copy=True, iterated_power=7, n_components=20, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "[ 0.6         0.46666667  0.53333333  0.48888889  0.73333333]\n",
      "Average accuracy on 5 subjects is 0.5644444444444445 with std. dev. of 0.09594236953299065.\n"
     ]
    }
   ],
   "source": [
    "print(clf_pipe.best_estimator_)  # What was the best classifier and parameters?\n",
    "print(best_scores)\n",
    "print(\"Average accuracy on {} subjects is {} with std. dev. of {}.\"\n",
    "      .format(n_subjs, best_scores.mean(), best_scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Novel contribution:** be creative and make one new discovery by adding an analysis, visualization, or optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('reduce_dim', PCA(copy=True, iterated_power=7, n_components=20, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classify', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))])\n",
      "0.688888888889\n"
     ]
    }
   ],
   "source": [
    "# Show that the pipeline results are far worse when we don't z-score\n",
    "\n",
    "# no scaling!!!\n",
    "pipe = Pipeline([\n",
    "        ('reduce_dim', PCA()),\n",
    "        ('classify', SVC(kernel=\"linear\")),\n",
    "    ])\n",
    "\n",
    "# PCA dimensions\n",
    "component_steps = [20, 40]\n",
    "\n",
    "# Classifier cost options\n",
    "c_steps = [10e-1, 10e0, 10e1]\n",
    "\n",
    "# Build the grid search dictionary\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7)], \n",
    "        'reduce_dim__n_components': component_steps,\n",
    "        'classify__C': c_steps,\n",
    "    },\n",
    "]\n",
    "\n",
    "clf_pipe = GridSearchCV(pipe, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "clf_pipe.fit(bold_data, labels);\n",
    "\n",
    "print(clf_pipe.best_estimator_)  # What was the best classifier and parameters?\n",
    "print(clf_pipe.best_score_) # What was the best classification score?\n",
    "\n",
    "#Note that this score is inferior to the classification accuracy on subject 5 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
